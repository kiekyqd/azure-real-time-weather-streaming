{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04d0c8a7-f410-412c-a30f-b57ecca00e20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sending a test to the Event Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7997421-7759-4153-bea7-69a8d96bcabb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved Event Hub connection string from Key Vault.\nSuccessfully connected to Event Hub.\nEvent successfully sent to Event Hub!\nEvent Hub producer closed.\n"
     ]
    }
   ],
   "source": [
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "\n",
    "# Configuration: Retrieve Event Hub connection string securely from Azure Key Vault in Databricks\n",
    "try:\n",
    "    eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"eventhub-connection-string\")\n",
    "    print(\"Successfully retrieved Event Hub connection string from Key Vault.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving secret from Key Vault: {e}\")\n",
    "    raise\n",
    "\n",
    "# Event Hub Name\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "\n",
    "# Initialize the Event Hub producer client\n",
    "try:\n",
    "    producer = EventHubProducerClient.from_connection_string(\n",
    "        conn_str=eventhub_connection_string, \n",
    "        eventhub_name=EVENT_HUB_NAME\n",
    "    )\n",
    "    print(\"Successfully connected to Event Hub.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Event Hub producer: {e}\")\n",
    "    raise\n",
    "\n",
    "# Function to send events to Azure Event Hub\n",
    "def send_event(event):\n",
    "    try:\n",
    "        # Create a batch for sending events\n",
    "        event_data_batch = producer.create_batch()\n",
    "        \n",
    "        # Add the event data to the batch (converted to JSON string)\n",
    "        event_data_batch.add(EventData(json.dumps(event)))\n",
    "        \n",
    "        # Send the batch to Event Hub\n",
    "        producer.send_batch(event_data_batch)\n",
    "        print(\"Event successfully sent to Event Hub!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending event: {e}\")\n",
    "\n",
    "# Sample event data to be sent to Event Hub\n",
    "event = {\n",
    "    \"event_id\": 2222,\n",
    "    \"event_name\": \"Key Vault Test\"\n",
    "}\n",
    "\n",
    "# Send the event\n",
    "send_event(event)\n",
    "\n",
    "# Close the producer client after sending events\n",
    "producer.close()\n",
    "print(\"Event Hub producer closed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df1fa7bb-4e71-48c1-83e3-9d623f07f1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### API Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a2dd9c2-8678-4d80-8623-6dc735943361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved Weather API key from Key Vault.\nCurrent Weather:\n{\n   \"location\": {\n      \"name\": \"Auckland\",\n      \"region\": \"\",\n      \"country\": \"New Zealand\",\n      \"lat\": -36.8667,\n      \"lon\": 174.7667,\n      \"tz_id\": \"Pacific/Auckland\",\n      \"localtime_epoch\": 1742557132,\n      \"localtime\": \"2025-03-22 00:38\"\n   },\n   \"current\": {\n      \"last_updated_epoch\": 1742556600,\n      \"last_updated\": \"2025-03-22 00:30\",\n      \"temp_c\": 16.2,\n      \"temp_f\": 61.2,\n      \"is_day\": 0,\n      \"condition\": {\n         \"text\": \"Clear\",\n         \"icon\": \"//cdn.weatherapi.com/weather/64x64/night/113.png\",\n         \"code\": 1000\n      },\n      \"wind_mph\": 2.5,\n      \"wind_kph\": 4.0,\n      \"wind_degree\": 251,\n      \"wind_dir\": \"WSW\",\n      \"pressure_mb\": 1019.0,\n      \"pressure_in\": 30.09,\n      \"precip_mm\": 0.0,\n      \"precip_in\": 0.0,\n      \"humidity\": 88,\n      \"cloud\": 0,\n      \"feelslike_c\": 16.2,\n      \"feelslike_f\": 61.2,\n      \"windchill_c\": 15.2,\n      \"windchill_f\": 59.4,\n      \"heatindex_c\": 15.2,\n      \"heatindex_f\": 59.4,\n      \"dewpoint_c\": 12.4,\n      \"dewpoint_f\": 54.4,\n      \"vis_km\": 10.0,\n      \"vis_miles\": 6.0,\n      \"uv\": 0.0,\n      \"gust_mph\": 4.6,\n      \"gust_kph\": 7.5\n   }\n}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Retrieve API key securely from Azure Key Vault in Databricks\n",
    "try:\n",
    "    weather_api_key = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"weatherapikey\")\n",
    "    print(\"Successfully retrieved Weather API key from Key Vault.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving API key from Key Vault: {e}\")\n",
    "    raise\n",
    "\n",
    "# Define base URL and endpoint for the Weather API\n",
    "base_url = \"http://api.weatherapi.com/v1\"\n",
    "current_weather_url = f\"{base_url}/current.json\"\n",
    "\n",
    "# Specify the location for which weather data is requested\n",
    "location = \"Auckland\"  # Change to preferred city\n",
    "\n",
    "# Define query parameters for the API request\n",
    "params = {\n",
    "    \"key\": weather_api_key,\n",
    "    \"q\": location\n",
    "}\n",
    "\n",
    "# Make the GET request to the Weather API\n",
    "response = requests.get(current_weather_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    current_weather = response.json()\n",
    "    print(\"Current Weather:\")\n",
    "    print(json.dumps(current_weather, indent=3))\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "170d55c3-62c4-415f-b3c6-8926f8d862a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Complete code for getting weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab1b7ddb-a57c-429c-b102-1e2142413700",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data: {\n   \"name\": \"Auckland\",\n   \"region\": \"\",\n   \"country\": \"New Zealand\",\n   \"lat\": -36.8667,\n   \"lon\": 174.7667,\n   \"localtime\": \"2025-03-22 00:41\",\n   \"temp_c\": 16.2,\n   \"is_day\": 0,\n   \"condition_text\": \"Clear\",\n   \"condition_icon\": \"//cdn.weatherapi.com/weather/64x64/night/113.png\",\n   \"wind_kph\": 4.0,\n   \"wind_degree\": 251,\n   \"wind_dir\": \"WSW\",\n   \"pressure_in\": 30.09,\n   \"precip_in\": 0.0,\n   \"humidity\": 88,\n   \"cloud\": 0,\n   \"feelslike_c\": 16.2,\n   \"uv\": 0.0,\n   \"air_quality\": {\n      \"co\": 159.1,\n      \"no2\": 2.59,\n      \"o3\": 60.0,\n      \"so2\": 2.59,\n      \"pm2_5\": 2.59,\n      \"pm10\": 2.775,\n      \"us-epa-index\": 1,\n      \"gb-defra-index\": 1\n   },\n   \"alerts\": [],\n   \"forecast\": [\n      {\n         \"date\": \"2025-03-22\",\n         \"maxtemp_c\": 22.4,\n         \"mintemp_c\": 14.8,\n         \"condition\": \"Sunny\"\n      },\n      {\n         \"date\": \"2025-03-23\",\n         \"maxtemp_c\": 22.4,\n         \"mintemp_c\": 14.2,\n         \"condition\": \"Sunny\"\n      },\n      {\n         \"date\": \"2025-03-24\",\n         \"maxtemp_c\": 22.4,\n         \"mintemp_c\": 15.4,\n         \"condition\": \"Patchy rain nearby\"\n      }\n   ]\n}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Function to handle API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": f\"Error: {response.status_code}, {response.text}\"}\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"aqi\": \"yes\"\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get forecast weather data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get weather alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"alerts\": \"yes\"\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to flatten and merge weather data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        \"name\": location_data.get(\"name\"),\n",
    "        \"region\": location_data.get(\"region\"),\n",
    "        \"country\": location_data.get(\"country\"),\n",
    "        \"lat\": location_data.get(\"lat\"),\n",
    "        \"lon\": location_data.get(\"lon\"),\n",
    "        \"localtime\": location_data.get(\"localtime\"),\n",
    "        \"temp_c\": current.get(\"temp_c\"),\n",
    "        \"is_day\": current.get(\"is_day\"),\n",
    "        \"condition_text\": condition.get(\"text\"),\n",
    "        \"condition_icon\": condition.get(\"icon\"),\n",
    "        \"wind_kph\": current.get(\"wind_kph\"),\n",
    "        \"wind_degree\": current.get(\"wind_degree\"),\n",
    "        \"wind_dir\": current.get(\"wind_dir\"),\n",
    "        \"pressure_in\": current.get(\"pressure_in\"),\n",
    "        \"precip_in\": current.get(\"precip_in\"),\n",
    "        \"humidity\": current.get(\"humidity\"),\n",
    "        \"cloud\": current.get(\"cloud\"),\n",
    "        \"feelslike_c\": current.get(\"feelslike_c\"),\n",
    "        \"uv\": current.get(\"uv\"),\n",
    "        \"air_quality\": {\n",
    "            \"co\": air_quality.get(\"co\"),\n",
    "            \"no2\": air_quality.get(\"no2\"),\n",
    "            \"o3\": air_quality.get(\"o3\"),\n",
    "            \"so2\": air_quality.get(\"so2\"),\n",
    "            \"pm2_5\": air_quality.get(\"pm2_5\"),\n",
    "            \"pm10\": air_quality.get(\"pm10\"),\n",
    "            \"us-epa-index\": air_quality.get(\"us-epa-index\"),\n",
    "            \"gb-defra-index\": air_quality.get(\"gb-defra-index\")\n",
    "        },\n",
    "        \"alerts\": [\n",
    "            {\n",
    "                \"headline\": alert.get(\"headline\"),\n",
    "                \"severity\": alert.get(\"severity\"),\n",
    "                \"description\": alert.get(\"desc\"),\n",
    "                \"instruction\": alert.get(\"instruction\")\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        \"forecast\": [\n",
    "            {\n",
    "                \"date\": day.get(\"date\"),\n",
    "                \"maxtemp_c\": day.get(\"day\", {}).get(\"maxtemp_c\"),\n",
    "                \"mintemp_c\": day.get(\"day\", {}).get(\"mintemp_c\"),\n",
    "                \"condition\": day.get(\"day\", {}).get(\"condition\", {}).get(\"text\")\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "# Main function to fetch and display weather data\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1\"\n",
    "    location = \"Auckland\"  # Change to preferred city\n",
    "    \n",
    "    # Retrieve API key securely from Azure Key Vault\n",
    "    try:\n",
    "        weather_api_key = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"weatherapikey\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving API key: {e}\")\n",
    "        return\n",
    "\n",
    "    # Fetch weather data from APIs\n",
    "    current_weather = get_current_weather(base_url, weather_api_key, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weather_api_key, location, 3)\n",
    "    alerts = get_alerts(base_url, weather_api_key, location)\n",
    "\n",
    "    # Merge and flatten data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "    print(\"Weather Data:\", json.dumps(merged_data, indent=3))\n",
    "\n",
    "# Execute the main function\n",
    "fetch_weather_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5dce2c5-eb49-409f-b5c3-c4dafc66dcca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sending the complete weather data to the Event HUB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87d3adea-7d83-4d22-98a8-2b703dfed00e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event successfully sent to Event Hub!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "\n",
    "# Retrieve Event Hub connection string securely from Azure Key Vault\n",
    "eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"eventhub-connection-string\")\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    try:\n",
    "        event_data_batch = producer.create_batch()\n",
    "        event_data_batch.add(EventData(json.dumps(event)))\n",
    "        producer.send_batch(event_data_batch)\n",
    "        print(\"Event successfully sent to Event Hub!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending event: {e}\")\n",
    "\n",
    "# Function to handle API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": f\"Error: {response.status_code}, {response.text}\"}\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast Data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/alerts.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "# Main function to fetch and send weather data\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Auckland\"  # Change to preferred city\n",
    "    \n",
    "    # Retrieve API key securely from Azure Key Vault\n",
    "    try:\n",
    "        weather_api_key = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"weatherapikey\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving API key: {e}\")\n",
    "        return\n",
    "\n",
    "    # Get data from API\n",
    "    current_weather = get_current_weather(base_url, weather_api_key, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weather_api_key, location, 3)\n",
    "    alerts = get_alerts(base_url, weather_api_key, location)\n",
    "\n",
    "    # Flatten and merge data\n",
    "    merged_data = flatten_data(current_weather, forecast_weather, alerts)\n",
    "\n",
    "    # Sending the weather data to Event Hub\n",
    "    send_event(merged_data)\n",
    "\n",
    "# Execute the main function\n",
    "fetch_weather_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2f9d0ce-8201-4b8a-856e-889b0247a862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sending the weather data in streaming fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa2e5c28-e7ad-401f-87d6-0f57089c2f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\nEvent successfully sent to Event Hub!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Event Hub configuration\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"eventhub-connection-string\")\n",
    "weatherapikey = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"weatherapikey\")\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    try:\n",
    "        event_data_batch = producer.create_batch()\n",
    "        event_data_batch.add(EventData(json.dumps(event)))\n",
    "        producer.send_batch(event_data_batch)\n",
    "        print(\"Event successfully sent to Event Hub!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending event: {e}\")\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": f\"Error: {response.status_code}, {response.text}\"}\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast Data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "# Function to fetch weather data\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Auckland\"\n",
    "    \n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "    \n",
    "    return flatten_data(current_weather, forecast_weather, alerts)\n",
    "\n",
    "# Function to process streaming data batch\n",
    "def process_batch(batch_df, batch_id):\n",
    "    try:\n",
    "        weather_data = fetch_weather_data()\n",
    "        send_event(weather_data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending events in batch {batch_id}: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Set up a streaming source (rate source for testing purposes)\n",
    "streaming_df = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
    "\n",
    "# Write the streaming data using foreachBatch to send weather data to Event Hub\n",
    "query = streaming_df.writeStream.foreachBatch(process_batch).start()\n",
    "\n",
    "query.awaitTermination()\n",
    "\n",
    "# Close the producer after termination\n",
    "producer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "953bb95f-fa63-4992-9b62-e3130f2bba50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sending the weather data to Event HUB in every 30 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f67e8a5b-6d4d-4b0f-81df-1dc8f0927878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event successfully sent to Event Hub!\nEvent Sent at 2025-03-21 12:03:31.803130\nEvent successfully sent to Event Hub!\nEvent Sent at 2025-03-21 12:04:01.860791\nEvent successfully sent to Event Hub!\nEvent Sent at 2025-03-21 12:04:33.009374\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:464)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:571)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:51)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:51)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:553)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:846)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:872)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:871)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:926)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:719)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:633)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:656)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:628)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:537)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:529)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:495)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.eventhub import EventHubProducerClient, EventData\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Event Hub configuration\n",
    "EVENT_HUB_NAME = \"weatherstreamingeventhub\"\n",
    "eventhub_connection_string = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"eventhub-connection-string\")\n",
    "weatherapikey = dbutils.secrets.get(scope=\"key-vault-scope\", key=\"weatherapikey\")\n",
    "\n",
    "# Initialize the Event Hub producer\n",
    "producer = EventHubProducerClient.from_connection_string(conn_str=eventhub_connection_string, eventhub_name=EVENT_HUB_NAME)\n",
    "\n",
    "# Function to send events to Event Hub\n",
    "def send_event(event):\n",
    "    try:\n",
    "        event_data_batch = producer.create_batch()\n",
    "        event_data_batch.add(EventData(json.dumps(event)))\n",
    "        producer.send_batch(event_data_batch)\n",
    "        print(\"Event successfully sent to Event Hub!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending event: {e}\")\n",
    "\n",
    "# Function to handle the API response\n",
    "def handle_response(response):\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {\"error\": f\"Error: {response.status_code}, {response.text}\"}\n",
    "\n",
    "# Function to get current weather and air quality data\n",
    "def get_current_weather(base_url, api_key, location):\n",
    "    current_weather_url = f\"{base_url}/current.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"aqi\": 'yes'\n",
    "    }\n",
    "    response = requests.get(current_weather_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Forecast Data\n",
    "def get_forecast_weather(base_url, api_key, location, days):\n",
    "    forecast_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        \"key\": api_key,\n",
    "        \"q\": location,\n",
    "        \"days\": days\n",
    "    }\n",
    "    response = requests.get(forecast_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Function to get Alerts\n",
    "def get_alerts(base_url, api_key, location):\n",
    "    alerts_url = f\"{base_url}/forecast.json\"\n",
    "    params = {\n",
    "        'key': api_key,\n",
    "        'q': location,\n",
    "        \"alerts\": 'yes'\n",
    "    }\n",
    "    response = requests.get(alerts_url, params=params)\n",
    "    return handle_response(response)\n",
    "\n",
    "# Flatten and merge the data\n",
    "def flatten_data(current_weather, forecast_weather, alerts):\n",
    "    location_data = current_weather.get(\"location\", {})\n",
    "    current = current_weather.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {})\n",
    "    air_quality = current.get(\"air_quality\", {})\n",
    "    forecast = forecast_weather.get(\"forecast\", {}).get(\"forecastday\", [])\n",
    "    alert_list = alerts.get(\"alerts\", {}).get(\"alert\", [])\n",
    "\n",
    "    flattened_data = {\n",
    "        'name': location_data.get('name'),\n",
    "        'region': location_data.get('region'),\n",
    "        'country': location_data.get('country'),\n",
    "        'lat': location_data.get('lat'),\n",
    "        'lon': location_data.get('lon'),\n",
    "        'localtime': location_data.get('localtime'),\n",
    "        'temp_c': current.get('temp_c'),\n",
    "        'is_day': current.get('is_day'),\n",
    "        'condition_text': condition.get('text'),\n",
    "        'condition_icon': condition.get('icon'),\n",
    "        'wind_kph': current.get('wind_kph'),\n",
    "        'wind_degree': current.get('wind_degree'),\n",
    "        'wind_dir': current.get('wind_dir'),\n",
    "        'pressure_in': current.get('pressure_in'),\n",
    "        'precip_in': current.get('precip_in'),\n",
    "        'humidity': current.get('humidity'),\n",
    "        'cloud': current.get('cloud'),\n",
    "        'feelslike_c': current.get('feelslike_c'),\n",
    "        'uv': current.get('uv'),\n",
    "        'air_quality': {\n",
    "            'co': air_quality.get('co'),\n",
    "            'no2': air_quality.get('no2'),\n",
    "            'o3': air_quality.get('o3'),\n",
    "            'so2': air_quality.get('so2'),\n",
    "            'pm2_5': air_quality.get('pm2_5'),\n",
    "            'pm10': air_quality.get('pm10'),\n",
    "            'us-epa-index': air_quality.get('us-epa-index'),\n",
    "            'gb-defra-index': air_quality.get('gb-defra-index')\n",
    "        },\n",
    "        'alerts': [\n",
    "            {\n",
    "                'headline': alert.get('headline'),\n",
    "                'severity': alert.get('severity'),\n",
    "                'description': alert.get('desc'),\n",
    "                'instruction': alert.get('instruction')\n",
    "            }\n",
    "            for alert in alert_list\n",
    "        ],\n",
    "        'forecast': [\n",
    "            {\n",
    "                'date': day.get('date'),\n",
    "                'maxtemp_c': day.get('day', {}).get('maxtemp_c'),\n",
    "                'mintemp_c': day.get('day', {}).get('mintemp_c'),\n",
    "                'condition': day.get('day', {}).get('condition', {}).get('text')\n",
    "            }\n",
    "            for day in forecast\n",
    "        ]\n",
    "    }\n",
    "    return flattened_data\n",
    "\n",
    "# Function to fetch weather data\n",
    "def fetch_weather_data():\n",
    "    base_url = \"http://api.weatherapi.com/v1/\"\n",
    "    location = \"Auckland\"\n",
    "    \n",
    "    current_weather = get_current_weather(base_url, weatherapikey, location)\n",
    "    forecast_weather = get_forecast_weather(base_url, weatherapikey, location, 3)\n",
    "    alerts = get_alerts(base_url, weatherapikey, location)\n",
    "    \n",
    "    return flatten_data(current_weather, forecast_weather, alerts)\n",
    "\n",
    "# Function to process streaming data batch\n",
    "last_sent_time = datetime.now() - timedelta(seconds=30)\n",
    "\n",
    "# Main program: Process batch data from streaming source\n",
    "def process_batch(batch_df, batch_id):\n",
    "    global last_sent_time\n",
    "    try:\n",
    "        # Get the current time\n",
    "        current_time = datetime.now()\n",
    "        \n",
    "        # Check if at least 30 seconds have passed since the last event was sent\n",
    "        if (current_time - last_sent_time).total_seconds() >= 30:\n",
    "            \n",
    "            # Fetch the latest weather data\n",
    "            weather_data = fetch_weather_data()\n",
    "            \n",
    "            # Send the fetched weather data to Event Hub\n",
    "            send_event(weather_data)\n",
    "            \n",
    "            # Update the last sent time to the current time\n",
    "            last_sent_time = current_time\n",
    "            print(f'Event Sent at {last_sent_time}')\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending events in batch {batch_id}: {str(e)}\")\n",
    "        raise e\n",
    "\n",
    "# Set up a streaming source (rate source for testing purposes)\n",
    "streaming_df = spark.readStream.format(\"rate\").option(\"rowsPerSecond\", 1).load()\n",
    "\n",
    "# Write the streaming data using foreachBatch to send weather data to Event Hub\n",
    "query = streaming_df.writeStream.foreachBatch(process_batch).start()\n",
    "\n",
    "query.awaitTermination()\n",
    "\n",
    "# Close the producer after termination\n",
    "producer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b18c77f9-346e-4081-930b-abc47353f865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4985a6a0-099f-4647-9334-c0fbc8aa7e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "weather-streaming-notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}